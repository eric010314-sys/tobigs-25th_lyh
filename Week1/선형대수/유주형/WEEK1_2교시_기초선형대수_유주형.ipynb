{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d41915c",
      "metadata": {
        "id": "9d41915c"
      },
      "source": [
        "## 1주차 - 기초선형대수 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "607e69d9",
      "metadata": {
        "id": "607e69d9"
      },
      "source": [
        "안녕하세요 투빅스 여러분 24기 이상민입니다.   \n",
        "1주차 정규세션 다들 고생하셨습니다.   \n",
        "모두에게 유익한 시간이었기를 바랍니다.   \n",
        "선형대수내용과 관련하여 간단한 과제들을 출제했습니다.   \n",
        "첫 주차이기에 간단한 내용들로만 구성해보았으니 문제를 잘 읽어보시고 과제 수행해주시기바랍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15b98b0c",
      "metadata": {
        "id": "15b98b0c"
      },
      "source": [
        "### Q1. 이론문제(서술형)\n",
        "#### 우리는 신경망이 단순히 선형변환(행렬 곱)만으로 이루어지지 않고, 중간에 비선형 함수(Non-linear function)가 반드시 필요하다는 것을 배웠습니다.\n",
        "\n",
        "##### 1-1. 선형변환을 여러 번 겹쳐서 수행했을 때 여전히 '선형적'인 성질이 유지된다는 것이 어떤 의미인지 설명하고,\n",
        "\n",
        "##### 1-2. 이를 통해 딥러닝 모델에서 활성화 함수(Activation Function)와 같은 비선형성이 왜 필수적인지 서술하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e0b3d12",
      "metadata": {
        "id": "4e0b3d12"
      },
      "source": [
        "---\n",
        "**정답 입력**\n",
        "\n",
        "1-1 : '선형적'의 정의는 가산성(additivity)과 동차성(homogeneity)를 만족한다는 것을 의미한다. 다시 말해, T(x+y) = T(x)+T(y), 그리고 T(ax) = aT(x)의 두 조건을 만족하면 선형 변환이라는 뜻이다.\n",
        "\n",
        "그러므로 서로 다른 선형 변환 T_1 = Ax, T_2 = Bx에 대해서 T_2(T_1(x))를 연속해서 적용하면 B(Ax) = (BA)x가 되므로 하나의 행렬곱으로 합쳐지는 것을 볼 수 있다. 즉, 선형 변환을 여러 번 적용한다는 것은 또 다른 하나의 선형 변환을 생성하게 된다.\n",
        "\n",
        "기하학적으로는, 선형 변환이 가능하게 하는 일이 회전, 확대/축소, 좌표축 재정의가 된다. 선형 변환을 겹쳤을 때 선형적 성질이 유지되지 않는다고 말하려면 공간을 접거나, 분리하거나 휘게 만들어야 하는데, 선형 변환 반복해도 공간의 형태는 변하지 않는다.\n",
        "\n",
        "결론적으로 선형적 성질이 유지된다는 것은 입력과 출력 사이의 관계가 항상 하나의 직선으로 설명 가능하다는 것이며, 딥러닝의 관점에서는 층을 많이 쌓아도 계속 동일한 선형 변환이 유지된다는 의미이다. (표현력/결정 경계의 형태 변화가 없음) 이는 1-2 질문과 직접적으로 연결된다.\n",
        "\n",
        "1-2 : 1-1의 논의를 정리하면, 선형 변환을 여러 번 겹쳐도 전체 모델은 하나의 선형 변환으로 축약되므로, 딥러닝 모델이 표현할 수 있는 함수의 형태에는 근본적인 한계가 존재한다.\n",
        "\n",
        "이와 관련해 Universal Approximation Theorem(유니버설 근사 정리)는 비선형 활성화 함수를 포함한 신경망이 충분한 노드를 가진 단일 은닉층을 가질 경우 임의의 염속 함수를 원하는 정확도로 근사할 수 있음을 이론적으로 보장하는 딥러닝의 핵심 기반 이론이다.\n",
        "\n",
        "이는 활성화 함수(ReLU를 주로 사용하게 됨)에 의해 신경망이 단순한 선형 결합을 넘어 복잡한 비선형 관계까지 표현할 수 있음을 의미하며, 딥러닝 모델이 다양한 실제 문제에서 강력한 표현력을 갖는 이유를 설명해준다. 다만 이 정리는 함수의 존재성을 보장할 뿐, 실제 학습 과정에서 해당 함수를 효율적으로 찾을 수 있음을 보장하는 것은 아니라는 점에서 최적화와 일반화 문제는 별도로 고려해야 한다.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5daedf55",
      "metadata": {
        "id": "5daedf55"
      },
      "source": [
        "### Q2. 개념 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc15efb5",
      "metadata": {
        "id": "fc15efb5"
      },
      "source": [
        "#### 2-1. **[내적(Dot Product)과 Norm]**   \n",
        "##### 두 벡터의 유사도를 판단하거나 길이를 구할 때 사용되는 함수입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f34a19fb",
      "metadata": {
        "id": "f34a19fb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_similarity_components(v1, v2):\n",
        "    \"\"\"\n",
        "    v1, v2: numpy array (1D vectors)\n",
        "    반환값: 두 벡터의 내적 값, v1의 norm, v2의 norm\n",
        "    \"\"\"\n",
        "    # 1. 두 벡터의 내적(Dot Product)을 계산하세요.\n",
        "    dot_prod = np.dot(v1, v2)\n",
        "\n",
        "    # 2. 각 벡터의 크기(Norm, L2 Norm)를 계산하세요.\n",
        "    norm_v1 = np.linalg.norm(v1)\n",
        "    norm_v2 = np.linalg.norm(v2)\n",
        "\n",
        "    return dot_prod, norm_v1, norm_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9ac9c2ab",
      "metadata": {
        "id": "9ac9c2ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef723c3-06df-4ed0-848b-d02291a5887a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "내적값 : 56.0, v1의 norm : 5.0, v2의 norm : 13.0\n"
          ]
        }
      ],
      "source": [
        "# 함수 확인\n",
        "v1 = np.array([3.0, 4.0])  # 예시 벡터 1\n",
        "v2 = np.array([12.0, 5.0])  # 예시 벡터 2\n",
        "out = calculate_similarity_components(v1, v2)\n",
        "\n",
        "print(f\"내적값 : {out[0]}, v1의 norm : {out[1]}, v2의 norm : {out[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제로 내적을 손으로 계산하면,  3x12 + 4x5 = 36+20 = 56이고, ||v1|| = sqrt(3^2 + 4^2) = 5 , ||v2|| = sqrt(12^2 + 5^2) = 13 이므로 결과와 일치한다."
      ],
      "metadata": {
        "id": "TJ3TvU7z5HqP"
      },
      "id": "TJ3TvU7z5HqP"
    },
    {
      "cell_type": "markdown",
      "id": "cf443749",
      "metadata": {
        "id": "cf443749"
      },
      "source": [
        "#### 2-2. **[선형변환 (행렬 곱)]**\n",
        "##### 입력 벡터를 다른 차원의 공간으로 매핑하는 선형변환 과정입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5a7e127e",
      "metadata": {
        "id": "5a7e127e"
      },
      "outputs": [],
      "source": [
        "def linear_transformation(x, W, b):\n",
        "    \"\"\"\n",
        "    x: 입력 벡터 (input features)\n",
        "    W: 가중치 행렬 (weight matrix)\n",
        "    b: 편향 벡터 (bias)\n",
        "    반환값: 선형변환 결과 z = Wx + b\n",
        "    \"\"\"\n",
        "    # 1. 행렬 곱(Matrix Multiplication) Wx를 수행하세요.\n",
        "    # 힌트: numpy의 행렬 곱 연산자(@) 또는 np.dot, np.matmul 사용\n",
        "    wx = W @ x\n",
        "\n",
        "    # 2. 편향(bias)을 더하세요.\n",
        "    z = wx + b\n",
        "\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "01b29ac6",
      "metadata": {
        "id": "01b29ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa588719-5eab-44eb-ed80-37da3ab9e94f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.6 0.3]\n"
          ]
        }
      ],
      "source": [
        "# 함수 확인\n",
        "x = np.array([1.0, 2.0])  # 예시 input vector\n",
        "W = np.array([[0.5, 1.0], [1.5, -0.5]])  # 예시 weight matrix\n",
        "b = np.array([0.1, -0.2])  # 예시 bias vector\n",
        "\n",
        "print(linear_transformation(x, W, b))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1125f25d",
      "metadata": {
        "id": "1125f25d"
      },
      "source": [
        "#### 2-3. **[비선형성 (ReLU 함수)]**\n",
        "##### 선형변환 결과에 비선형성을 부여하는 활성화 함수입니다. 빈칸을 채워 함수를 완성해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad0e5215",
      "metadata": {
        "id": "ad0e5215"
      },
      "source": [
        "![ReLU](https://velog.velcdn.com/images/sasganamabeer/post/4ea7fb74-2c3a-423f-8e47-bde64cddebb2/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%2C%202021-05-13%2015-27-54.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8cc17868",
      "metadata": {
        "id": "8cc17868"
      },
      "outputs": [],
      "source": [
        "def relu_function(z):\n",
        "    \"\"\"\n",
        "    z: 선형변환을 거친 값\n",
        "    반환값: 0보다 작으면 0, 0보다 크면 그대로 반환 (max(0, z))\n",
        "    \"\"\"\n",
        "    # numpy의 maximum 함수 등을 사용하여 ReLU를 구현하세요.\n",
        "    a = np.maximum(0, z)\n",
        "    return a"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "176c1447",
      "metadata": {
        "id": "176c1447"
      },
      "source": [
        "### Q3. 응용 문제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a1508a9",
      "metadata": {
        "id": "6a1508a9"
      },
      "source": [
        "위 2번 문제에서 작성한 함수들(calculate_similarity_components, linear_transformation, relu_function)을 활용하여 아래 문제를 해결하는 코드를 작성하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1474f9b",
      "metadata": {
        "id": "f1474f9b"
      },
      "source": [
        "#### 간단한 유사도 기반 분류기 구현.\n",
        "입력 데이터 x가 주어졌을 때, 1차적으로 선형 변환과 비선형 변환을 거쳐 특징(feature)을 추출하고, 이 추출된 특징이 기준 벡터(reference vector)와 얼마나 유사한지 코사인 유사도(Cosine Similarity)로 판단합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6b4d9ed7",
      "metadata": {
        "id": "6b4d9ed7"
      },
      "outputs": [],
      "source": [
        "def forward_and_evaluate(x, W, b, ref_vector):\n",
        "\n",
        "    # 1. 선형 변환\n",
        "\n",
        "  z = linear_transformation(x, W, b)\n",
        "\n",
        "    # 2. 비선형 활성화\n",
        "\n",
        "  feature = relu_function(z)\n",
        "\n",
        "    # 3. 코사인 유사도 계산\n",
        "\n",
        "  dot_prod, norm_feature, norm_ref = calculate_similarity_components(feature, ref_vector)\n",
        "\n",
        "    # 코사인 유사도 공식 적용 (분모가 0이 아님을 가정)\n",
        "\n",
        "  cosine_similarity = dot_prod / (norm_feature * norm_ref)\n",
        "\n",
        "  return cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c04901de",
      "metadata": {
        "id": "c04901de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1e1ba4-9a6e-4509-f081-410d3ba173f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6708203932499369\n"
          ]
        }
      ],
      "source": [
        "# 테스트 코드\n",
        "x = np.array([1, 2])\n",
        "W = np.array([[1, -1], [2, 0], [0, 1]]) # 3x2 행렬\n",
        "b = np.array([0, 1, -1])\n",
        "ref = np.array([1, 1, 0])\n",
        "print(forward_and_evaluate(x, W, b, ref))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d09e9a",
      "metadata": {
        "id": "f4d09e9a"
      },
      "source": [
        "+자유롭게 다른 활성화함수를 정의하는 등을 통해 추가적으로 학습하셔도 좋을것 같습니다.\n",
        "\n",
        "고생하셨습니다.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18d2d1b1",
      "metadata": {
        "id": "18d2d1b1"
      },
      "source": [
        "### **과제 완료 후 잊지말고 꼭 깃허브에 제출해주시기바랍니다.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}